{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training and Testing a Classification Model</h3>\n",
    "\n",
    "In this notebook, I will build a training/test/validation set of sentences from Medium articles. I will label the set and extract features. Then I will train a model and cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "from sklearn import linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step One:</b> Separate out training from test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to postgresql db\n",
    "username = 'kimberly'\n",
    "dbname = 'medium'\n",
    "\n",
    "dbe = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get df, drop missing data\n",
    "df = pd.read_sql('articles', dbe, index_col='postid')\n",
    "df = df.dropna(axis=0,how='any')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Functions to format row of the df, as well as do text processing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to convert nlikes and ncomments to integer\n",
    "def convert_K(nstr):\n",
    "    spl = nstr.split('K')\n",
    "    if len(spl)==1:\n",
    "        return int(float(spl[0]))\n",
    "    else:\n",
    "        return int(float(spl[0])*1000)\n",
    "    \n",
    "def convert_str(nstr):\n",
    "    nstr = nstr.replace(',','')\n",
    "    if nstr=='':\n",
    "        return None\n",
    "    else:\n",
    "        return int(nstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_paragraph(par,swords):\n",
    "    '''takes one paragraph (string); performs lower, tokenize, remove punctuation/stop words'''\n",
    "    par = par.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(par)\n",
    "    nstop_tokens = [t for t in tokens if (t not in swords and t not in string.punctuation)]\n",
    "    return nstop_tokens                      \n",
    "\n",
    "def process_text_paragraphs(atext,origdb,swords):\n",
    "    '''atext is a list or series of textstrings (one from each article), \n",
    "    origdb is a list or series of corresponding original databse IDs (ints from 0-4)'''\n",
    "    # initial text split\n",
    "    alist = [initial_text_split(a,int(o)) for a,o in zip(atext,origdb)]\n",
    "        \n",
    "    # remove very long articles\n",
    "    removed_articles = [aix for aix,a in enumerate(alist) if len(a)>=250]\n",
    "    alist = [a for a in alist if len(a)<250]\n",
    "    \n",
    "    # process each paragraph\n",
    "    alist = [[process_paragraph(p,swords) for p in a] for a in alist]\n",
    "    \n",
    "    return [alist,removed_articles]\n",
    "\n",
    "def process_text_sentences(atext,origdb,swords):\n",
    "    '''same processing, but does a sentence breakup rather than paragraph'''\n",
    "    # initial text split\n",
    "    alist = [initial_text_split(a,int(o)) for a,o in zip(atext,origdb)]\n",
    "    \n",
    "    # remove very long articles\n",
    "    removed_articles = [aix for aix,a in enumerate(alist) if len(a)>=250]\n",
    "    alist = [a for a in alist if len(a)<250]\n",
    "    \n",
    "    # change paragraph splits to sentence splits\n",
    "    alist = [plist_to_slist(plist) for plist in alist]\n",
    "    \n",
    "    # process each paragraph\n",
    "    alist = [[process_paragraph(p,swords) for p in a] for a in alist]\n",
    "    \n",
    "    return [alist,removed_articles]\n",
    "\n",
    "def initial_text_split(article_text,origdb):\n",
    "    '''takes article text and original db and performs appropriate splitting'''\n",
    "    if origdb in [1,2,3]:\n",
    "        # split into paragraphs\n",
    "        plist = article_text.split('/n')\n",
    "\n",
    "        # remove \\n symbols from within words\n",
    "        plist = [p.replace('\\n','') for p in plist]\n",
    "    \n",
    "    else:\n",
    "        # split into paragraphs\n",
    "        plist = article_text.split('\\n')\n",
    "        \n",
    "    return plist\n",
    "\n",
    "def plist_to_slist(plist):\n",
    "    '''changes a list of paragraphs to a list of sentences'''\n",
    "    spl = [re.split('[/./!/?]',par) for par in plist]\n",
    "    return [s for p in spl for s in p if len(s)>1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>popdate</th>\n",
       "      <th>url</th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>highlight</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>ncomments</th>\n",
       "      <th>ntags</th>\n",
       "      <th>origdb</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>npar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9e5dc29e33ce</th>\n",
       "      <td>A hacker stole $31M of Ether — how it happened...</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>https://medium.freecodecamp.org/a-hacker-stole...</td>\n",
       "      <td>8bc4e5f8b505</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>Blaming mistakes on individuals is pointless, ...</td>\n",
       "      <td>2.2K</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ethereum,Blockchain,Security,Technology,Startup</td>\n",
       "      <td>Yesterday, a hacker pulled off the second bigg...</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          title     popdate  \\\n",
       "postid                                                                        \n",
       "9e5dc29e33ce  A hacker stole $31M of Ether — how it happened...  2017-07-21   \n",
       "\n",
       "                                                            url        userid  \\\n",
       "postid                                                                          \n",
       "9e5dc29e33ce  https://medium.freecodecamp.org/a-hacker-stole...  8bc4e5f8b505   \n",
       "\n",
       "                    username  \\\n",
       "postid                         \n",
       "9e5dc29e33ce  Haseeb Qureshi   \n",
       "\n",
       "                                                      highlight nlikes  \\\n",
       "postid                                                                   \n",
       "9e5dc29e33ce  Blaming mistakes on individuals is pointless, ...   2.2K   \n",
       "\n",
       "             ncomments  ntags  origdb  \\\n",
       "postid                                  \n",
       "9e5dc29e33ce       100    5.0     4.0   \n",
       "\n",
       "                                                         tags  \\\n",
       "postid                                                          \n",
       "9e5dc29e33ce  Ethereum,Blockchain,Security,Technology,Startup   \n",
       "\n",
       "                                                           text   npar  \n",
       "postid                                                                  \n",
       "9e5dc29e33ce  Yesterday, a hacker pulled off the second bigg...  104.0  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.url == 'https://medium.freecodecamp.org/a-hacker-stole-31m-of-ether-how-it-happened-and-what-it-means-for-ethereum-9e5dc29e33ce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now we will use these functions to format the text</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop word corpus and process text\n",
    "swords = stopwords.words('english')\n",
    "processing_output = process_text_sentences(df.text,df.origdb,swords)\n",
    "ptext = processing_output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop too-long articles\n",
    "removed_articles = processing_output[1]\n",
    "dfDrop = df.drop(df.index[removed_articles])\n",
    "for rem in removed_articles:\n",
    "    del ptext[rem]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process highlights and titles\n",
    "htext = [plist_to_slist([hilite]) for hilite in dfDrop.highlight]\n",
    "htext = [[process_paragraph(hsent,swords) for hsent in art] for art in htext]\n",
    "ttext = [plist_to_slist([title]) for title in dfDrop.title]\n",
    "ttext = [[process_paragraph(tsent,swords) for tsent in art] for art in ttext]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now, we will LABEL each sentence as 1 or 0 (in highlight or not)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL whether each sentence is in the highlight\n",
    "plabel = []\n",
    "for a,art in enumerate(ptext):\n",
    "    alabel = []\n",
    "    for s in art:\n",
    "        alabel.append(any([(s==hs) for hs in htext[a]]))\n",
    "    plabel.append(alabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457\n",
      "3183\n"
     ]
    }
   ],
   "source": [
    "# find articles with no highlight in ptext\n",
    "len(plabel)\n",
    "h_in_ptext = [any(a) for a in plabel]\n",
    "print(len(plabel) - sum(h_in_ptext))\n",
    "print(sum(h_in_ptext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that several (about 1/4) of the articles with a highlight do NOT contain the highlight in the p-text (i.e., in the text scraped from p tags in the html).\n",
    "<br><br>\n",
    "These can still be used as negative examples. We will check to see if there is a corresponding positive example, and if not, use the highlight itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get the dataframe together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format rows in dataframe\n",
    "dfDrop.nlikes = dfDrop.nlikes.map(convert_K)\n",
    "dfDrop.ncomments = dfDrop.ncomments.map(convert_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add processed text to df\n",
    "dfDrop.text = ptext\n",
    "dfDrop.highlight = htext\n",
    "dfDrop.title = ttext\n",
    "dfDrop['label'] = plabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add article wcount to df\n",
    "wcount = [sum([len(par) for par in art]) for art in ptext]\n",
    "dfDrop['wcount'] = wcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data will include (about) 80% of the articles in the dataframe. \n",
    "First, we separate out a random set of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose test/train sets\n",
    "test_ix = randint(0,999)\n",
    "dfTest = dfDrop.iloc([test_ix])\n",
    "dfTrain = dfDrop.drop(dfDrop.index[test_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Set up training data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>popdate</th>\n",
       "      <th>url</th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>highlight</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>ncomments</th>\n",
       "      <th>ntags</th>\n",
       "      <th>origdb</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>npar</th>\n",
       "      <th>wcount</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1015a0f4961d</th>\n",
       "      <td>[[day, one, president, obama, first, family, l...</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>https://medium.com/@ObamaWhiteHouse/day-one-pr...</td>\n",
       "      <td>ca9f8f16893b</td>\n",
       "      <td>The Obama White House</td>\n",
       "      <td>[[today, air, force, one, touched, havana, fir...</td>\n",
       "      <td>336</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cuba,Twitter,Cuba Trip</td>\n",
       "      <td>[[hola, desde, cuba], [today, air, force, one,...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>522</td>\n",
       "      <td>[False, True, False, False, False, False, Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101a407e8c61</th>\n",
       "      <td>[[make, makes]]</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>https://medium.com/the-mission/you-dont-make-i...</td>\n",
       "      <td>5ce28105ffbc</td>\n",
       "      <td>Jon Westenberg</td>\n",
       "      <td>[[make, makes]]</td>\n",
       "      <td>549</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Entrepreneurship,Startup,Life</td>\n",
       "      <td>[[always, wanted, make], [grew, dreaming, rock...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030d29376f1</th>\n",
       "      <td>[[ux, infinite, scrolling, vs], [pagination]]</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>https://uxplanet.org/ux-infinite-scrolling-vs-...</td>\n",
       "      <td>bcab753a4d4e</td>\n",
       "      <td>Nick Babich</td>\n",
       "      <td>[[instances, infinite, scrolling, effective], ...</td>\n",
       "      <td>1910</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>UX,Design,User Experience,UX Design</td>\n",
       "      <td>[[use, infinite, scrolling, pagination, conten...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>850</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315016b299</th>\n",
       "      <td>[[lesson, stereotypes]]</td>\n",
       "      <td>2016-08-20</td>\n",
       "      <td>https://medium.com/@mramsburg85/a-lesson-on-st...</td>\n",
       "      <td>d38709ba4e06</td>\n",
       "      <td>Michael Ramsburg</td>\n",
       "      <td>[[stereotypes, strip, culture, like, mountains...</td>\n",
       "      <td>583</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stereotypes,Appalachia,Culture,Essay,Opinion</td>\n",
       "      <td>[[stereotypes], [mrs], [mitchell, sixth, grade...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>381</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10321e751c6d</th>\n",
       "      <td>[[republican, never, trump, means]]</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>https://medium.com/@ccmccain/for-this-republic...</td>\n",
       "      <td>4e965facd5f9</td>\n",
       "      <td>Caroline McCain</td>\n",
       "      <td>[[trump, statement, view, unforgivable, speaks...</td>\n",
       "      <td>2500</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hillary Clinton,Donald Trump,Never Trump,2016 ...</td>\n",
       "      <td>[[know, know, woman, fiercely, loyal, friends,...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>993</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          title     popdate  \\\n",
       "postid                                                                        \n",
       "1015a0f4961d  [[day, one, president, obama, first, family, l...  2016-03-21   \n",
       "101a407e8c61                                    [[make, makes]]  2016-06-02   \n",
       "1030d29376f1      [[ux, infinite, scrolling, vs], [pagination]]  2016-05-02   \n",
       "10315016b299                            [[lesson, stereotypes]]  2016-08-20   \n",
       "10321e751c6d                [[republican, never, trump, means]]  2016-07-30   \n",
       "\n",
       "                                                            url        userid  \\\n",
       "postid                                                                          \n",
       "1015a0f4961d  https://medium.com/@ObamaWhiteHouse/day-one-pr...  ca9f8f16893b   \n",
       "101a407e8c61  https://medium.com/the-mission/you-dont-make-i...  5ce28105ffbc   \n",
       "1030d29376f1  https://uxplanet.org/ux-infinite-scrolling-vs-...  bcab753a4d4e   \n",
       "10315016b299  https://medium.com/@mramsburg85/a-lesson-on-st...  d38709ba4e06   \n",
       "10321e751c6d  https://medium.com/@ccmccain/for-this-republic...  4e965facd5f9   \n",
       "\n",
       "                           username  \\\n",
       "postid                                \n",
       "1015a0f4961d  The Obama White House   \n",
       "101a407e8c61         Jon Westenberg   \n",
       "1030d29376f1            Nick Babich   \n",
       "10315016b299       Michael Ramsburg   \n",
       "10321e751c6d        Caroline McCain   \n",
       "\n",
       "                                                      highlight  nlikes  \\\n",
       "postid                                                                    \n",
       "1015a0f4961d  [[today, air, force, one, touched, havana, fir...     336   \n",
       "101a407e8c61                                    [[make, makes]]     549   \n",
       "1030d29376f1  [[instances, infinite, scrolling, effective], ...    1910   \n",
       "10315016b299  [[stereotypes, strip, culture, like, mountains...     583   \n",
       "10321e751c6d  [[trump, statement, view, unforgivable, speaks...    2500   \n",
       "\n",
       "              ncomments  ntags  origdb  \\\n",
       "postid                                   \n",
       "1015a0f4961d       15.0    3.0     3.0   \n",
       "101a407e8c61       37.0    3.0     3.0   \n",
       "1030d29376f1       46.0    4.0     3.0   \n",
       "10315016b299      103.0    5.0     3.0   \n",
       "10321e751c6d      302.0    5.0     3.0   \n",
       "\n",
       "                                                           tags  \\\n",
       "postid                                                            \n",
       "1015a0f4961d                             Cuba,Twitter,Cuba Trip   \n",
       "101a407e8c61                      Entrepreneurship,Startup,Life   \n",
       "1030d29376f1                UX,Design,User Experience,UX Design   \n",
       "10315016b299       Stereotypes,Appalachia,Culture,Essay,Opinion   \n",
       "10321e751c6d  Hillary Clinton,Donald Trump,Never Trump,2016 ...   \n",
       "\n",
       "                                                           text  npar  wcount  \\\n",
       "postid                                                                          \n",
       "1015a0f4961d  [[hola, desde, cuba], [today, air, force, one,...  20.0     522   \n",
       "101a407e8c61  [[always, wanted, make], [grew, dreaming, rock...  21.0     393   \n",
       "1030d29376f1  [[use, infinite, scrolling, pagination, conten...  34.0     850   \n",
       "10315016b299  [[stereotypes], [mrs], [mitchell, sixth, grade...  12.0     381   \n",
       "10321e751c6d  [[know, know, woman, fiercely, loyal, friends,...  45.0     993   \n",
       "\n",
       "                                                          label  \n",
       "postid                                                           \n",
       "1015a0f4961d  [False, True, False, False, False, False, Fals...  \n",
       "101a407e8c61  [False, False, False, False, False, False, Fal...  \n",
       "1030d29376f1  [False, False, False, False, False, False, Fal...  \n",
       "10315016b299  [False, False, False, False, False, False, Fal...  \n",
       "10321e751c6d  [False, False, False, False, False, False, Fal...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sentence-wise split:</b> We set up the data by sentence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dataframe for sentences...\n",
    "dfS = pd.DataFrame()\n",
    "\n",
    "for art in dfTrain.index:\n",
    "    slist = dfTrain.text[art]\n",
    "    for nsent in range(len(slist)):\n",
    "        sent = slist[nsent]\n",
    "        dfRow = pd.DataFrame([art,sent,len(sent),nsent,len(slist),dfTrain.label[art][nsent]])\n",
    "        dfRow = dfRow.T\n",
    "        dfRow.columns = ['postid','sentence','swcount','sposition','alength','slabel']\n",
    "        dfS = pd.concat([dfS,dfRow])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434741, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>swcount</th>\n",
       "      <th>sposition</th>\n",
       "      <th>alength</th>\n",
       "      <th>slabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015a0f4961d</td>\n",
       "      <td>[hola, desde, cuba]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015a0f4961d</td>\n",
       "      <td>[today, air, force, one, touched, havana, firs...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015a0f4961d</td>\n",
       "      <td>[question, remarkable, moment, relationship, u...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015a0f4961d</td>\n",
       "      <td>[also, landmark, progress, made, since, presid...</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015a0f4961d</td>\n",
       "      <td>[trip, also, professionally, personally, meani...</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         postid                                           sentence swcount  \\\n",
       "0  1015a0f4961d                                [hola, desde, cuba]       3   \n",
       "0  1015a0f4961d  [today, air, force, one, touched, havana, firs...       9   \n",
       "0  1015a0f4961d  [question, remarkable, moment, relationship, u...       9   \n",
       "0  1015a0f4961d  [also, landmark, progress, made, since, presid...      29   \n",
       "0  1015a0f4961d  [trip, also, professionally, personally, meani...      19   \n",
       "\n",
       "  sposition alength slabel  \n",
       "0         0      52  False  \n",
       "0         1      52   True  \n",
       "0         2      52  False  \n",
       "0         3      52  False  \n",
       "0         4      52  False  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfS.shape)\n",
    "dfS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfS.to_sql('sentences_train',dbe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding article data:</b> We perform a merge to add article-wise data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434741, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "postid       False\n",
       "sentence     False\n",
       "swcount      False\n",
       "sposition    False\n",
       "alength      False\n",
       "slabel       False\n",
       "title        False\n",
       "nlikes       False\n",
       "npar         False\n",
       "wcount       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left merge dfS -> dfTrain on postid\n",
    "\n",
    "dfX = pd.merge(dfS, dfTrain[['title','nlikes','npar','wcount']], \n",
    "               how='left', left_on='postid', left_index=False, right_index=True, sort=False)\n",
    "print(dfX.shape)\n",
    "nsamp = dfX.shape[0]\n",
    "dfX.isnull().any()\n",
    "#dfX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5920"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX.loc[dfX.slabel].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now, we set up the model itself.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikitlearn logistic regression... fit (with 2/3 of X, y from above)\n",
    "\n",
    "dfY = dfX['slabel']\n",
    "dfX = dfX[['swcount','sposition','alength','nlikes','wcount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289827,)\n",
      "(289827, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl = math.floor(2*nsamp/3)\n",
    "ytrain = dfY.iloc[0:spl].astype(int)\n",
    "Xtrain = dfX.iloc[0:spl]\n",
    "ytest = dfY.iloc[spl:].astype(int)\n",
    "Xtest = dfX.iloc[spl:]\n",
    "print(ytrain.shape)\n",
    "print(Xtrain.shape)\n",
    "lrm = linear_model.LogisticRegression()\n",
    "lrm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98661270344 0.98661270344\n",
      "0.985922685179 0.985922685179\n"
     ]
    }
   ],
   "source": [
    "# test on the 2/3 of training set\n",
    "print(lrm.score(Xtrain,ytrain), 1 - ytrain.mean())\n",
    "\n",
    "# test on the other 1/3 of X, y\n",
    "print(lrm.score(Xtest,ytest), 1 - ytest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is predicting \"no highlight\" for every sample. This is what I expected, given the extremely unbalanced nature of the data. I will try balancing techniques (just as soon as I get Flask to work...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make ROC curve to compare thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding New Features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute average tf-idf score for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cosine similarity of sentence to article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cosine similarity of sentence to title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find sentiment of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find sentiment of each article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Balancing Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsample negative sentences so ratio is ~2:1 neg:pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upsample positive sentence with data augmentation\n",
    "\n",
    "# ideas: do they cluster in tf-idf space? try jitter...\n",
    "#        shuffle/swap words from other highlights?\n",
    "#        redistribute among highlights in the same article..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
